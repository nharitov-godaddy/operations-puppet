# Notify the Data Engineering and product analytics teams about services on these hosts
contactgroups: 'admins,analytics,team-product-analytics'

nagios_group: analytics_eqiad
cluster: analytics
profile::admin::groups:
  - analytics-product-users
  - analytics-admins

profile::contacts::role_contacts: ['Data Engineering']
profile::airflow::airflow_version: '2.5.1-py3.10-20230228'

profile::hadoop::common::hadoop_cluster_name: 'analytics-hadoop'
profile::hive::client::hive_service_name: 'analytics-hive'

profile::kerberos::keytabs::keytabs_metadata:
  - role: 'analytics-product'
    owner: 'analytics-product'
    group: 'analytics-product'
    filename: 'analytics-product.keytab'
# Context https://phabricator.wikimedia.org/T278353#6976509
profile::kerberos::client::dns_canonicalize_hostname: false

profile::java::java_packages:
  - version: '8'
    variant: 'jdk'
profile::java::extra_args:
  JAVA_TOOL_OPTIONS: "-Dfile.encoding=UTF-8"

profile::airflow::database_host_default: an-db1001.eqiad.wmnet
# Set up airflow instances.
profile::airflow::instances:
  # airflow@analytics_product instance.
  analytics_product:
    ferm_srange: $ANALYTICS_NETWORKS
    # Since we set security: kerberos a keytab must be deployed for the service_user.
    service_user: analytics-product
    service_group: analytics-product
    monitoring_enabled: true
    connections:
      analytics-hive:
        conn_type: hive_metastore
        host: analytics-hive.eqiad.wmnet
        port: 9083
        extra_dejson: {'auth_mechanism': 'GSSAPI'}
    airflow_config:
      datahub:
        enabled: False
