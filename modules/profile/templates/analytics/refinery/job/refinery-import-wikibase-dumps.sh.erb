#!/bin/bash
<%#- SPDX-License-Identifier: Apache-2.0 -%>
# NOTE: This file is managed by puppet
#

# Rsync wikidata dumps to HDFS
/usr/local/bin/hdfs-rsync \
    --recursive           \
    --times               \
    --delete              \
    --prune-empty-dirs    \
    --chmod=go-w          \
    --include "/[0-9]*"   \
    --include "<%= @include_pattern %>" \
    --exclude "**"        \
    file:<%= @local_source %> \
    hdfs://analytics-hadoop<%= @hdfs_destination %>

# Touch flag in all folders to let Airflow start jobs
for f in $(/usr/bin/hdfs dfs -ls <%= @hdfs_destination %> | awk '{print $8}')
do
    /usr/bin/hdfs dfs -touchz $f/_IMPORTED
done
